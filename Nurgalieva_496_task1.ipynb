{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Questions (0.5 балла)\n",
    "##### Вопрос 1: Объясните, чем отличается k-nearrest Neighbours от k-weighted nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В  k-nearrest Neighbours мы не учитываем расстояние от нашего объекта до его соседей, этот метод более подвержен неоднозначности классификации. Т.е пусть у нас k=2, первый сосед относится к классу 2 и находится ближе к объекту, который мы хотим классифицировать, а второй сосед относится к классу 1 и находится подальше. Тогда  k-nearrest Neighbours выдаст коллизию, а k-weighted nearest neighbours покажет, что наш объект принадлежит второму классу, потому что первый сосед находится ближе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 2: Как изменяется абсолютное расстояние между объектами выборки при изменении метрики минковского с $p=1$ до  $p=\\infty$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rho_1(x, y) = \\sum\\limits_{i=1}^{d} |x_i - y_i|$\n",
    "\n",
    "$\\rho_{\\infty}(x, y) = max_{i=1 ... d} |x_i - y_i|$\n",
    "\n",
    "при $p=1$ расстояние между объектами будет больше, чем при $p = \\infty$, тк $max_{i=1 ... d} |x_i - y_i| \\leq \\sum\\limits_{i=1}^{d} |x_i - y_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 3: Поясните, в чем суть проклятия размерности?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При росте размерности объекты становятся более удаленными друг от друга, т.е например чтобы с большой вероятностью найти несколько ближайших соседей точки $(0,0,...0)$ среди равномерно распределенных точек в $d$-мерном кубе со стороной $[0; 1]$ нужно отступать на расстояния, быстро растущие с ростом $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 4: Что такое метрический отступ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть объект $ u \\in X$. Введём понятие функции близости  $u$ к объектам класса $y \\in Y$: $\\Gamma_y(u)$ - просто складывает все объекты из класса $y$ с их весами относительно $u$. А теперь на основе этой функции построим классификатор, который объекту сопоставляет класс с наибольший функцией близости:\n",
    "\n",
    "Теперь оценим, насколько объект обучающей выборки \"близок\" своему классу. Для объекта $x_i$ мы знаем, к какому классу он принадлежит - $y_i$, проверим, насколько хорошо наш объект подходит под свой класс:\n",
    "\n",
    "$M(x_i) = Г_{y_i}(x_i)  - max_{y \\in Y \\backslash y_i} Г_y(x_i)$ - мы взяли суммарный вес относительно $x_i$ всех объетов из класса $y_i$ и вычли максимальный вес объектов из другого класса, это называется метрический отступ. Чем больше эта величина, тем лучше объект подходит под свой класс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 5: На какие типы можно разделить объекты обучающей выборки с точки значения значения метрического отступа? Какие объекты стоит исключить из выборки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого объекта выборки оценим величину отступа, и отсортируем по этой величине. Получим пять условных классов объектов\n",
    "\n",
    "Эталонные - объекты, которые хорошо подходят под свой класс, имеют большой положительный отступ. Можно брать за основу для классификации\n",
    "\n",
    "Неинформативные - объекты, которые тоже имеют положительный отступ, но не добавляют никакой дополнительной информации к эталонным объектам. Наличие объектов такого класса характерно для избыточной выборки\n",
    "\n",
    "Пограничные - с почти нулевым отступом, классификация таких объектов может измениться при изменении метрики или других каких-то параметров\n",
    "\n",
    "Ошибочные - неверно классифицированные объекты. Ошибка может быть допущена из-за неудачного выбора модели\n",
    "\n",
    "Шумовые объекты или выбросы - с большим отрицательным отступом. Т.е они окружены объектами другого класса. Такие объекты следует исключать из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 6: Что такое функционал эмпирического риска? Приведите примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы определить, насколько хорошо работает наш алгоритм, введём понятие $L(a, x) - $ функция потерь (насколько алгоритм $a$ ошибается на $x \\in X$).\n",
    "\n",
    "Она может быть разной в зависимости от задачи:\n",
    "\n",
    "$L(a, x) = I(x) $ - индикаторная функция, подходит для задач классификации.\n",
    "\n",
    "$L(a, x) = |a(x) - y(x)| $ - показывает, на сколько ответ алгоритма отличается от настоящего. Для задачи регрессии.\n",
    "\n",
    "А теперь усредним все \"потери\", получится эмпирическая функция риска:\n",
    "\n",
    "$Q(a, X^{l}) = \\frac{1}{l}\\sum\\limits_{i=1}^l L(a, x_{i})$ - таким образом, этот функционал показывает, насколько хорошо работает алгоритм на всей обучающей выборке. Нужно подобрать такой алгоритм $a$, чтобы значение функционала было как можно меньше \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос 7: В чём суть явления переобучения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явление переобучения состоит в том, что наш алгоритм слишком подстроился под обучающую выборку, но не открыл общей закономерности. Или, что то же самое, эмпирическая функция мала на данных из обучающей выборки, но на контрольной выборке принимает большие значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вопрос 8: Напишите формулу для complete cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Суть метода complete cross validation состоит в том, чтобы разбить всю нашу выборку размера $L$ на части размера $l$ всеми способами, т.е $ N = C^{l}_{L}$, $X = X^{l}_{n} \\cup X^{k}_{n}, n \\in \\{ 1 ... N\\}, k = L-l$, для каждого $ n \\in \\{ 1 ... N\\}$ обучим алгоритм $ a $ на обучающей выборке $X^{l}_{n}$, проверим на контрольной $X^{k}_{n}$ и усредним ошибку по всем элементам из контрольной выборки, а теперь усредним значения по всем разбиениям:\n",
    "\n",
    "$CCV(\\mu, X^{L}) =\\frac{1}{N}\\sum\\limits_{n=1}^N \\frac{1}{k} \\sum\\limits_{x_i \\in X^{k}_{n}} I\\{a(x_i, X^{l}_{n}) \\neq y_i\\}$ - это будет оценка качества нашего алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
