
[+] General Parameters:
Training data:	train_without_counter.txt
Validation data:	val_without_counter.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@5
Test metric:	NDCG@5
Feature normalization: No
Model file: LambdaMART_without_counter

[+] LambdaMART's Parameters:
No. of trees: 1000
No. of leaves: 10
No. of threshold candidates: 256
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [train_without_counter.txt]: 0... Reading feature file [train_without_counter.txt]... [Done.]            
(96 ranked lists, 792 entries read)
Reading feature file [val_without_counter.txt]: 0... Reading feature file [val_without_counter.txt]... [Done.]            
(30 ranked lists, 198 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@5-T  | NDCG@5-V  | 
---------------------------------
1       | 0.6606    | 0.7341    | 
2       | 0.6912    | 0.7276    | 
3       | 0.6985    | 0.722     | 
4       | 0.7024    | 0.7145    | 
5       | 0.7024    | 0.7145    | 
6       | 0.7052    | 0.7145    | 
7       | 0.7143    | 0.7203    | 
8       | 0.7103    | 0.729     | 
9       | 0.715     | 0.7332    | 
10      | 0.715     | 0.7338    | 
11      | 0.7178    | 0.7338    | 
12      | 0.7188    | 0.7306    | 
13      | 0.7221    | 0.7306    | 
14      | 0.723     | 0.7306    | 
15      | 0.7285    | 0.7295    | 
16      | 0.7285    | 0.7295    | 
17      | 0.7285    | 0.7346    | 
18      | 0.7293    | 0.7346    | 
19      | 0.7328    | 0.7338    | 
20      | 0.7328    | 0.7346    | 
21      | 0.7367    | 0.7395    | 
22      | 0.7349    | 0.7387    | 
23      | 0.7401    | 0.7437    | 
24      | 0.7399    | 0.7437    | 
25      | 0.7463    | 0.7421    | 
26      | 0.7452    | 0.7421    | 
27      | 0.7452    | 0.7432    | 
28      | 0.7452    | 0.7372    | 
29      | 0.7447    | 0.7412    | 
30      | 0.746     | 0.7412    | 
31      | 0.7457    | 0.7412    | 
32      | 0.7479    | 0.7412    | 
33      | 0.7529    | 0.749     | 
34      | 0.7529    | 0.749     | 
35      | 0.754     | 0.749     | 
36      | 0.754     | 0.749     | 
37      | 0.754     | 0.749     | 
38      | 0.7559    | 0.749     | 
39      | 0.7553    | 0.7541    | 
40      | 0.7553    | 0.749     | 
41      | 0.7571    | 0.749     | 
42      | 0.7583    | 0.749     | 
43      | 0.7589    | 0.749     | 
44      | 0.7589    | 0.748     | 
45      | 0.7589    | 0.748     | 
46      | 0.7589    | 0.749     | 
47      | 0.7589    | 0.749     | 
48      | 0.7631    | 0.7472    | 
49      | 0.7631    | 0.7504    | 
50      | 0.7621    | 0.7504    | 
51      | 0.771     | 0.7641    | 
52      | 0.7708    | 0.758     | 
53      | 0.7707    | 0.7589    | 
54      | 0.7738    | 0.7589    | 
55      | 0.7742    | 0.7589    | 
56      | 0.7745    | 0.7589    | 
57      | 0.7746    | 0.7589    | 
58      | 0.7747    | 0.7589    | 
59      | 0.7746    | 0.7589    | 
60      | 0.777     | 0.7589    | 
61      | 0.7767    | 0.7589    | 
62      | 0.777     | 0.7589    | 
63      | 0.7771    | 0.7589    | 
64      | 0.777     | 0.7589    | 
65      | 0.779     | 0.7589    | 
66      | 0.7787    | 0.7589    | 
67      | 0.7799    | 0.7578    | 
68      | 0.7799    | 0.7578    | 
69      | 0.7799    | 0.7578    | 
70      | 0.7799    | 0.7578    | 
71      | 0.782     | 0.7546    | 
72      | 0.7817    | 0.7546    | 
73      | 0.7817    | 0.7546    | 
74      | 0.7815    | 0.7495    | 
75      | 0.7809    | 0.7495    | 
76      | 0.7815    | 0.7495    | 
77      | 0.7817    | 0.7489    | 
78      | 0.7817    | 0.7489    | 
79      | 0.7817    | 0.7489    | 
80      | 0.7817    | 0.7489    | 
81      | 0.7817    | 0.7489    | 
82      | 0.782     | 0.7489    | 
83      | 0.7818    | 0.7489    | 
84      | 0.7818    | 0.7489    | 
85      | 0.7818    | 0.7489    | 
86      | 0.7818    | 0.7489    | 
87      | 0.7817    | 0.7489    | 
88      | 0.7831    | 0.7489    | 
89      | 0.7832    | 0.7489    | 
90      | 0.7832    | 0.7489    | 
91      | 0.7832    | 0.7489    | 
92      | 0.7832    | 0.7489    | 
93      | 0.7844    | 0.7489    | 
94      | 0.7845    | 0.7489    | 
95      | 0.7843    | 0.7489    | 
96      | 0.7843    | 0.7489    | 
97      | 0.7843    | 0.7489    | 
98      | 0.7841    | 0.7489    | 
99      | 0.784     | 0.7489    | 
100     | 0.784     | 0.7489    | 
101     | 0.7843    | 0.7463    | 
102     | 0.7843    | 0.7463    | 
103     | 0.7843    | 0.7463    | 
104     | 0.7843    | 0.7463    | 
105     | 0.7843    | 0.7427    | 
106     | 0.7843    | 0.7427    | 
107     | 0.7849    | 0.7427    | 
108     | 0.784     | 0.7427    | 
109     | 0.784     | 0.7427    | 
110     | 0.7847    | 0.7427    | 
111     | 0.7847    | 0.7427    | 
112     | 0.786     | 0.7427    | 
113     | 0.7855    | 0.7427    | 
114     | 0.7862    | 0.7427    | 
115     | 0.7864    | 0.7427    | 
116     | 0.7864    | 0.7427    | 
117     | 0.7869    | 0.7427    | 
118     | 0.7867    | 0.7427    | 
119     | 0.7862    | 0.7427    | 
120     | 0.7872    | 0.7499    | 
121     | 0.7872    | 0.7499    | 
122     | 0.7872    | 0.7487    | 
123     | 0.7875    | 0.7487    | 
124     | 0.7875    | 0.7487    | 
125     | 0.7875    | 0.7487    | 
126     | 0.7875    | 0.7487    | 
127     | 0.788     | 0.7487    | 
128     | 0.788     | 0.7487    | 
129     | 0.788     | 0.7479    | 
130     | 0.7882    | 0.7479    | 
131     | 0.7908    | 0.7495    | 
132     | 0.7908    | 0.7495    | 
133     | 0.7908    | 0.7495    | 
134     | 0.7908    | 0.7495    | 
135     | 0.7908    | 0.7495    | 
136     | 0.7908    | 0.7495    | 
137     | 0.7908    | 0.749     | 
138     | 0.7908    | 0.749     | 
139     | 0.7908    | 0.749     | 
140     | 0.7908    | 0.749     | 
141     | 0.7908    | 0.749     | 
142     | 0.7908    | 0.749     | 
143     | 0.7908    | 0.749     | 
144     | 0.7908    | 0.749     | 
145     | 0.7908    | 0.749     | 
146     | 0.7908    | 0.749     | 
147     | 0.7908    | 0.7498    | 
148     | 0.791     | 0.7457    | 
149     | 0.7904    | 0.7457    | 
150     | 0.7906    | 0.7457    | 
151     | 0.7897    | 0.7457    | 
152     | 0.7915    | 0.7457    | 
---------------------------------
Finished sucessfully.
NDCG@5 on training data: 0.771
NDCG@5 on validation data: 0.7641
---------------------------------

Model saved to: LambdaMART_without_counter
