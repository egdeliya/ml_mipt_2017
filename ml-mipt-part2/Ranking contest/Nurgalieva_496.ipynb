{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_charact = ['.', ',', '^', '$', '*', '+', '?', '{', '}', '[', ']', '\\\\', '|', '(' ,')', '/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистит строки от метасимволов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_data(words_list):\n",
    "    for ind in range(len(words_list)):\n",
    "        for char in meta_charact:\n",
    "            words_list[ind] = words_list[ind].replace(char, '')\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считаем файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id document_id relevance\n",
       "1        1         184         2\n",
       "2        1          29         2\n",
       "3        1          31         2\n",
       "4        1          12         3\n",
       "5        1          51         3"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('relevance_train.csv', sep='\\t', names=['query_id', 'document_id', 'relevance'])\n",
    "train_set = train_set[1:]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>document_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id document_id\n",
       "1      126         974\n",
       "2      126        1326\n",
       "3      126         187\n",
       "4      126         969\n",
       "5      126         970"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('relevance_test.csv', sep=',', names=['query_id', 'document_id'])\n",
    "test_set = test_set[1:]\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what are the structural and aeroelastic proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what problems of heat conduction in composite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can a criterion be developed to show empirical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what chemical kinetic system is applicable to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      query\n",
       "query_id                                                   \n",
       "1         what similarity laws must be obeyed when const...\n",
       "2         what are the structural and aeroelastic proble...\n",
       "4         what problems of heat conduction in composite ...\n",
       "8         can a criterion be developed to show empirical...\n",
       "9         what chemical kinetic system is applicable to ..."
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_set = pd.read_csv('queries.csv', sep='\\t', names=['query_id', 'query'], header=None, index_col=['query_id'])\n",
    "queries_set = queries_set[1:]\n",
    "queries_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведём файл с документами к удобочитаемому виду. Для каждого документа будет хранить Counter от всех слов в документе, предварительно подготовленных nltk.word_tokenize. Автора, тему, дату не будем учитывать как отдельный признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents_set = pd.DataFrame(columns=['document_id', 'content'])\n",
    "\n",
    "# паттерны для id, date, author, ...\n",
    "patterns = ['.Id', '.A', '.T', '.B','.W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Documents.csv') as data_file:\n",
    "    doc_content = \"\"\n",
    "    for line in data_file:\n",
    "        is_pattern = False\n",
    "        if (line.startswith(id_pattern)):\n",
    "            if (doc_content != \"\"):\n",
    "                doc_content = nltk.word_tokenize(doc_content)\n",
    "                doc_content = clear_data(doc_content)\n",
    "                documents_set = documents_set.append({'document_id':doc_id, 'content':Counter(doc_content)}, ignore_index=True)\n",
    "            doc_content = \"\"  \n",
    "            doc_id = int(line[3:])\n",
    "            continue\n",
    "\n",
    "        for pattern in patterns:\n",
    "            if (line.startswith(pattern)):\n",
    "                is_pattern = True\n",
    "                break\n",
    "                \n",
    "        if (not is_pattern):\n",
    "            doc_content += \" \".join(line.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'experimental': 3, 'investigation': 2, 'of': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'simple': 3, 'shear': 3, 'flow': 7, 'past': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'the': 3, 'boundary': 2, 'layer': 2, 'in': 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'approximate': 2, 'solutions': 3, 'of': 5, 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'one-dimensional': 2, 'transient': 3, 'heat':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       content\n",
       "document_id                                                   \n",
       "1            {'experimental': 3, 'investigation': 2, 'of': ...\n",
       "2            {'simple': 3, 'shear': 3, 'flow': 7, 'past': 5...\n",
       "3            {'the': 3, 'boundary': 2, 'layer': 2, 'in': 2,...\n",
       "4            {'approximate': 2, 'solutions': 3, 'of': 5, 't...\n",
       "5            {'one-dimensional': 2, 'transient': 3, 'heat':..."
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_set = documents_set.set_index('document_id')\n",
    "documents_set = pd.DataFrame(documents_set)\n",
    "documents_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем данные для извлечения признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выберем все уникальные слова для всех запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_query_words = []\n",
    "unique_query_words = \"\".join(list(filter(lambda x : type(x)==str, np.array(queries_set['query']))))\n",
    "unique_query_words = np.unique(nltk.word_tokenize(unique_query_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберём из множества уникальных слов метасимволы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_query_words = clear_data(unique_query_words)\n",
    "unique_query_words = np.unique(unique_query_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединим train_set с запросами по ключу query_id, чтобы было легче смотреть не текст запроса. Эту же операцию можно было бы проделать для document_id, не это не работает :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>what similarity laws must be obeyed when const...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id document_id relevance  \\\n",
       "1        1         184         2   \n",
       "2        1          29         2   \n",
       "3        1          31         2   \n",
       "4        1          12         3   \n",
       "5        1          51         3   \n",
       "\n",
       "                                               query  \n",
       "1  what similarity laws must be obeyed when const...  \n",
       "2  what similarity laws must be obeyed when const...  \n",
       "3  what similarity laws must be obeyed when const...  \n",
       "4  what similarity laws must be obeyed when const...  \n",
       "5  what similarity laws must be obeyed when const...  "
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_res = train_set.join(queries_set, on='query_id', lsuffix=\"_train\", rsuffix=\"_queries\")\n",
    "train_set_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое проделываем с тестовымы данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>974</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>1326</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>187</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>969</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>970</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id document_id                                              query\n",
       "1      126         974  what are wind-tunnel corrections for a two-dim...\n",
       "2      126        1326  what are wind-tunnel corrections for a two-dim...\n",
       "3      126         187  what are wind-tunnel corrections for a two-dim...\n",
       "4      126         969  what are wind-tunnel corrections for a two-dim...\n",
       "5      126         970  what are wind-tunnel corrections for a two-dim..."
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_res = test_set.join(queries_set, on='query_id', lsuffix=\"_train\", rsuffix=\"_queries\")\n",
    "test_set_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для каждой пары запрос - документ составляем признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая записывает в файлы строки в нужном формате. А именно, для каждой пары запрос документ, для каждого уникального слова из множества уникальных слов в запросах, если это уникальное слово есть в запросе, то будем присать, сколько раз оно встретилось в данном документе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"с валидационной выборкой\"\"\" \n",
    "def write_to_file_with_val(train_file_name, val_file_name, train_set_res, counter=True, train_part=0.8):\n",
    "    with open(train_file_name, 'w') as features_matrix_train:\n",
    "        with open(val_file_name, 'w') as features_matrix_valid:\n",
    "            for row_ind in range(len(train_set_res)):\n",
    "                line = \"\"\n",
    "                \n",
    "                # считываем id запроса и документа, метрку релевантности, а также текст запроса \n",
    "                query_id = train_set_res.iloc[row_ind, 0]\n",
    "                document_id = train_set_res.iloc[row_ind, 1]\n",
    "                relevance = train_set_res.iloc[row_ind, 2]\n",
    "                query_content = train_set_res.iloc[row_ind, 3]\n",
    "                query_content = nltk.word_tokenize(str(query_content))\n",
    "                \n",
    "                # по id документа смотрим, какие слова и сколько раз встречались в этом документе\n",
    "                document_content_counter = documents_set.iloc[int(document_id), 0]\n",
    "\n",
    "                line += str(relevance) + ' ' + 'qid:' + str(query_id) + ' '\n",
    "\n",
    "                # для всех слов из множества уникальных слов смотрим, если \n",
    "                # это слово есть в запросе, то смотрим, сколько раз оно встречалось в документе\n",
    "                # и ставим это число, также можно попробовать вариант ставить 1, если слово также встечалось в документе\n",
    "                # и 0, если нет\n",
    "                for ind, word in enumerate(unique_query_words):\n",
    "                    if (not word in query_content):\n",
    "                        line += str(ind) + ':' + '0' + ' '\n",
    "                        continue\n",
    "                    if (counter):\n",
    "                        line += str(ind) + ':' + str(document_content_counter[word]) + ' '\n",
    "                    else:\n",
    "                        if (word in document_content_counter):\n",
    "                            line += str(ind) + ':' + str(1) + ' '\n",
    "                        else:\n",
    "                            line += str(ind) + ':' + str(0) + ' '\n",
    "\n",
    "                line += '\\n'\n",
    "\n",
    "                if (row_ind < round(len(train_set_res)*train_part)):\n",
    "                    features_matrix_train.write(line)\n",
    "                else:\n",
    "                    features_matrix_valid.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"делает то же самое, что и функция выше, но без валидации, а также ещё проверяет, \n",
    "что для document_id есть документ\"\"\"\n",
    "def write_to_file(file_name, data, counter=True, train=True):\n",
    "    with open(file_name, 'w') as features_matrix:\n",
    "        for row_ind in range(len(data)):\n",
    "            line = \"\"\n",
    "            query_id = data.iloc[row_ind, 0]\n",
    "            document_id = data.iloc[row_ind, 1]\n",
    "            \n",
    "            if (train):\n",
    "                relevance = train_set_res.iloc[row_ind, 2]\n",
    "                line += str(relevance) + ' ' + 'qid:' + str(query_id) + ' '\n",
    "                \n",
    "                query_content = data.iloc[row_ind, 3]\n",
    "\n",
    "            else:\n",
    "                line += '-1' + ' ' + 'qid:'+str(query_id) + ' '\n",
    "                query_content = data.iloc[row_ind, 2]\n",
    "\n",
    "            query_content = nltk.word_tokenize(str(query_content))\n",
    "\n",
    "            try:\n",
    "                document_content_counter = documents_set.iloc[int(document_id), 0]\n",
    "            except IndexError:\n",
    "                for ind in range(len(unique_query_words)):\n",
    "                    line += str(ind) + ':' + '0' + ' '\n",
    "                line += '\\n'\n",
    "                features_matrix.write(line)\n",
    "                continue\n",
    "\n",
    "            for ind, word in enumerate(unique_query_words):\n",
    "                if (not word in query_content):\n",
    "                    line += str(ind) + ':' + '0' + ' '\n",
    "                    continue\n",
    "                if (counter):\n",
    "                        line += str(ind) + ':' + str(document_content_counter[word]) + ' '\n",
    "                else:\n",
    "                    if (word in document_content_counter):\n",
    "                        line += str(ind) + ':' + str(1) + ' '\n",
    "                    else:\n",
    "                        line += str(ind) + ':' + str(0) + ' '\n",
    "\n",
    "            line += '\\n'\n",
    "            features_matrix.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train3.txt', 'w') as features_matrix_train:\n",
    "#     for row_ind in range(len(train_set_res)):\n",
    "#         line = \"\"\n",
    "#         query_id = train_set_res.iloc[row_ind, :][0]\n",
    "#         document_id = train_set_res.iloc[row_ind, :][1]\n",
    "#         relevance = train_set_res.iloc[row_ind, :][2]\n",
    "#         query_content = train_set_res.iloc[row_ind, :][3]\n",
    "#         query_content = nltk.word_tokenize(str(query_content))\n",
    "#         document_content_counter = documents_set.iloc[int(document_id), :][0]\n",
    "\n",
    "#         line += str(relevance) + ' ' + 'qid:' + str(query_id) + ' '\n",
    "\n",
    "#         for ind, word in enumerate(unique_query_words):\n",
    "#             if (not word in query_content):\n",
    "#                 line += str(ind) + ':' + '0' + ' '\n",
    "#                 continue\n",
    "#             line += str(ind) + ':' + str(document_content_counter[word]) + ' '\n",
    "\n",
    "#         line += '\\n'\n",
    "\n",
    "#         features_matrix_train.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test1.txt', 'w') as features_matrix:\n",
    "# #     i = 0\n",
    "#     for row_ind in range(len(test_set_res)):\n",
    "#         line = \"\"\n",
    "#         query_id = test_set_res.iloc[row_ind, :][0]\n",
    "#         document_id = test_set_res.iloc[row_ind, :][1]\n",
    "#         query_content = test_set_res.iloc[row_ind, :][2]\n",
    "#         query_content = nltk.word_tokenize(str(query_content))\n",
    "#         line += '-1' + ' ' + 'qid:'+str(query_id) + ' '\n",
    "# #         i += 1\n",
    "    \n",
    "#         try:\n",
    "#             document_content_counter = documents_set.iloc[int(document_id), :][0]\n",
    "#         except IndexError:\n",
    "# #             print(i, query_id, document_id)\n",
    "#             for ind in range(len(unique_query_words)):\n",
    "#                 line += str(ind) + ':' + '0' + ' '\n",
    "#             line += '\\n'\n",
    "#             features_matrix.write(line)\n",
    "#             continue\n",
    "\n",
    "#         for ind, word in enumerate(unique_query_words):\n",
    "#             if (not word in query_content):\n",
    "#                 line += str(ind) + ':' + '0' + ' '\n",
    "#                 continue\n",
    "#             line += str(ind) + ':' + str(document_content_counter[word]) + ' '\n",
    "\n",
    "#         line += '\\n'\n",
    "#         features_matrix.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file_with_val('train_with_counter.txt', 'val_with_counter.txt', train_set_res)\n",
    "\n",
    "write_to_file_with_val('train_without_counter.txt', 'val_without_counter.txt', train_set_res, counter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применяем алгорим LambdaMART к подготовленным данным в нужном формате"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем с Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! java -jar RankLib-2.1-patched.jar -train train_with_counter.txt -validate val_with_counter.txt -ranker 6 -metric2t NDCG@5 -save LambdaMART_with_counter > LambdaMART_with_counter.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь без Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! java -jar RankLib-2.1-patched.jar -train train_without_counter.txt -validate val_without_counter.txt -ranker 6 -metric2t NDCG@5 -save LambdaMART_without_counter > LambdaMART_without_counter.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С Counter работает лучше на train, но хуже на validation. Посмотрим на результаты моделей без валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file('train_with_counter_without_val.txt', train_set_res, train=True, counter=True)\n",
    "write_to_file('test_with_counter_without_val.txt', test_set_res, train=False, counter=True)\n",
    "\n",
    "write_to_file('train_without_counter_without_val.txt', train_set_res, counter=False, train=True)\n",
    "write_to_file('test_without_counter_without_val.txt', test_set_res, counter=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! java -jar RankLib-2.1-patched.jar -train train_with_counter_without_val.txt -ranker 6 -tree 400 -metric2t NDCG@5 -save LambdaMART_with_counter_without_val > LambdaMART_with_counter_without_val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! java -jar RankLib-2.1-patched.jar -train train_without_counter_without_val.txt -ranker 6 -tree 400 -metric2t NDCG@5 -save LambdaMART_without_counter_without_val > LambdaMART_without_counter_without_val.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метода без Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] General Parameters:\n",
      "Model file:\tLambdaMART_without_counter_without_val\n",
      "Feature normalization: No\n",
      "Model:\t\tLambdaMART\n",
      "\n",
      "Reading feature file [test_without_counter_without_val.txt]: 0... \n",
      "Reading feature file [test_without_counter_without_val.txt]... [Done.]            \n",
      "(100 ranked lists, 847 entries read)\n"
     ]
    }
   ],
   "source": [
    "!java -jar RankLib-2.1-patched.jar -load LambdaMART_without_counter_without_val -rank test_without_counter_without_val.txt -score score_without_counter_without_val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>974</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>1326</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>187</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>969</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>970</td>\n",
       "      <td>what are wind-tunnel corrections for a two-dim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id document_id                                              query\n",
       "0      126         974  what are wind-tunnel corrections for a two-dim...\n",
       "1      126        1326  what are wind-tunnel corrections for a two-dim...\n",
       "2      126         187  what are wind-tunnel corrections for a two-dim...\n",
       "3      126         969  what are wind-tunnel corrections for a two-dim...\n",
       "4      126         970  what are wind-tunnel corrections for a two-dim..."
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_res.index = range(len(test_rel))\n",
    "test_set_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.638955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.638955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.307772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.210904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.635123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         2\n",
       "0  126 -2.638955\n",
       "1  126 -2.638955\n",
       "2  126 -3.307772\n",
       "3  126 -2.210904\n",
       "4  126 -2.635123"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.read_csv('score_without_counter_without_val.txt', sep='\\t', header=None)\n",
    "score = score.drop(1, axis=1)\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.638955</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.638955</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.307772</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.210904</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>-2.635123</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         2     3\n",
       "0  126 -2.638955   974\n",
       "1  126 -2.638955  1326\n",
       "2  126 -3.307772   187\n",
       "3  126 -2.210904   969\n",
       "4  126 -2.635123   970"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score['3'] = test_set_res['document_id']\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId DocumentId\n",
       "0      126        971\n",
       "1      126        969\n",
       "2      126        970"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = score.groupby(0).apply(lambda x: x.sort_values([2],ascending=False).head(len(score)))\n",
    "output.index = range(len(output))\n",
    "output = pd.DataFrame(output)\n",
    "output = output.drop(2, axis=1)\n",
    "output.columns = ['QueryId','DocumentId']\n",
    "output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('out_without_counter_without_val.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое с Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] General Parameters:\n",
      "Model file:\tLambdaMART_with_counter_without_val\n",
      "Feature normalization: No\n",
      "Model:\t\tLambdaMART\n",
      "\n",
      "Reading feature file [test_with_counter_without_val.txt]: 0... \n",
      "Reading feature file [test_with_counter_without_val.txt]... [Done.]            \n",
      "(100 ranked lists, 847 entries read)\n"
     ]
    }
   ],
   "source": [
    "!java -jar RankLib-2.1-patched.jar -load LambdaMART_with_counter_without_val -rank test_with_counter_without_val.txt -score score_with_counter_without_val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>-4.302050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.933957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>-4.150296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.092625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.268303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         2\n",
       "0  126 -4.302050\n",
       "1  126 -3.933957\n",
       "2  126 -4.150296\n",
       "3  126 -1.092625\n",
       "4  126 -3.268303"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.read_csv('score_with_counter_without_val.txt', sep='\\t', header=None)\n",
    "score = score.drop(1, axis=1)\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score) == len(test_set_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>-4.302050</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.933957</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>-4.150296</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>-1.092625</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>-3.268303</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         2     3\n",
       "0  126 -4.302050   974\n",
       "1  126 -3.933957  1326\n",
       "2  126 -4.150296   187\n",
       "3  126 -1.092625   969\n",
       "4  126 -3.268303   970"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score['3'] = test_set_res['document_id']\n",
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId DocumentId\n",
       "0      126        969\n",
       "1      126        971\n",
       "2      126        942"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = score.groupby(0).apply(lambda x: x.sort_values([2],ascending=False).head(len(score)))\n",
    "output.index = range(len(output))\n",
    "output = pd.DataFrame(output)\n",
    "output = output.drop(2, axis=1)\n",
    "output.columns = ['QueryId','DocumentId']\n",
    "output.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('out_with_counter_without_val.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
