
[+] General Parameters:
Training data:	train_with_counter.txt
Validation data:	val_with_counter.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@5
Test metric:	NDCG@5
Feature normalization: No
Model file: LambdaMART_with_counter

[+] LambdaMART's Parameters:
No. of trees: 1000
No. of leaves: 10
No. of threshold candidates: 256
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [train_with_counter.txt]: 0... Reading feature file [train_with_counter.txt]... [Done.]            
(96 ranked lists, 792 entries read)
Reading feature file [val_with_counter.txt]: 0... Reading feature file [val_with_counter.txt]... [Done.]            
(30 ranked lists, 198 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@5-T  | NDCG@5-V  | 
---------------------------------
1       | 0.6725    | 0.708     | 
2       | 0.6916    | 0.7073    | 
3       | 0.695     | 0.7025    | 
4       | 0.7026    | 0.7047    | 
5       | 0.7201    | 0.7047    | 
6       | 0.7268    | 0.7027    | 
7       | 0.7255    | 0.6805    | 
8       | 0.7249    | 0.6877    | 
9       | 0.7309    | 0.6915    | 
10      | 0.7309    | 0.6915    | 
11      | 0.7318    | 0.6904    | 
12      | 0.7344    | 0.6959    | 
13      | 0.7351    | 0.6939    | 
14      | 0.7402    | 0.6938    | 
15      | 0.7433    | 0.6887    | 
16      | 0.744     | 0.6887    | 
17      | 0.7435    | 0.686     | 
18      | 0.7435    | 0.6858    | 
19      | 0.7435    | 0.6858    | 
20      | 0.7479    | 0.6864    | 
21      | 0.7515    | 0.6762    | 
22      | 0.7533    | 0.6762    | 
23      | 0.7496    | 0.6762    | 
24      | 0.7539    | 0.6762    | 
25      | 0.7558    | 0.6752    | 
26      | 0.7595    | 0.6752    | 
27      | 0.7608    | 0.6752    | 
28      | 0.7594    | 0.6752    | 
29      | 0.764     | 0.6791    | 
30      | 0.7641    | 0.6791    | 
31      | 0.7638    | 0.6758    | 
32      | 0.7684    | 0.6882    | 
33      | 0.7657    | 0.7093    | 
34      | 0.7666    | 0.7105    | 
35      | 0.7673    | 0.7142    | 
36      | 0.7679    | 0.7142    | 
37      | 0.7675    | 0.7113    | 
38      | 0.7719    | 0.7112    | 
39      | 0.7726    | 0.7191    | 
40      | 0.7779    | 0.7193    | 
41      | 0.7773    | 0.7181    | 
42      | 0.7785    | 0.7181    | 
43      | 0.7789    | 0.7235    | 
44      | 0.7833    | 0.7162    | 
45      | 0.7836    | 0.716     | 
46      | 0.7833    | 0.7207    | 
47      | 0.7832    | 0.7207    | 
48      | 0.7834    | 0.7207    | 
49      | 0.7819    | 0.7174    | 
50      | 0.7823    | 0.7227    | 
51      | 0.781     | 0.7224    | 
52      | 0.7801    | 0.7224    | 
53      | 0.7821    | 0.7224    | 
54      | 0.7853    | 0.7224    | 
55      | 0.7876    | 0.7293    | 
56      | 0.7876    | 0.7362    | 
57      | 0.7892    | 0.7293    | 
58      | 0.7906    | 0.7293    | 
59      | 0.792     | 0.7348    | 
60      | 0.7919    | 0.7316    | 
61      | 0.7924    | 0.7363    | 
62      | 0.7913    | 0.7347    | 
63      | 0.791     | 0.7358    | 
64      | 0.7939    | 0.736     | 
65      | 0.7954    | 0.7318    | 
66      | 0.7946    | 0.7293    | 
67      | 0.7956    | 0.7293    | 
68      | 0.7956    | 0.7261    | 
69      | 0.7953    | 0.726     | 
70      | 0.7957    | 0.7248    | 
71      | 0.7957    | 0.7242    | 
72      | 0.7958    | 0.7242    | 
73      | 0.7961    | 0.7253    | 
74      | 0.7969    | 0.7235    | 
75      | 0.7969    | 0.7247    | 
76      | 0.7969    | 0.7273    | 
77      | 0.7969    | 0.7192    | 
78      | 0.7977    | 0.7192    | 
79      | 0.7969    | 0.7192    | 
80      | 0.7976    | 0.719     | 
81      | 0.7968    | 0.719     | 
82      | 0.7973    | 0.7271    | 
83      | 0.7973    | 0.7271    | 
84      | 0.7976    | 0.7266    | 
85      | 0.7976    | 0.7266    | 
86      | 0.7976    | 0.7266    | 
87      | 0.7976    | 0.7271    | 
88      | 0.7967    | 0.7271    | 
89      | 0.7978    | 0.7266    | 
90      | 0.7993    | 0.7266    | 
91      | 0.8003    | 0.7199    | 
92      | 0.7988    | 0.7203    | 
93      | 0.799     | 0.7328    | 
94      | 0.799     | 0.7328    | 
95      | 0.801     | 0.7328    | 
96      | 0.8       | 0.7345    | 
97      | 0.7999    | 0.735     | 
98      | 0.8013    | 0.735     | 
99      | 0.8013    | 0.7342    | 
100     | 0.8014    | 0.7308    | 
101     | 0.8014    | 0.7308    | 
102     | 0.8014    | 0.7286    | 
103     | 0.8041    | 0.7253    | 
104     | 0.8074    | 0.7194    | 
105     | 0.8068    | 0.7201    | 
106     | 0.8071    | 0.7211    | 
107     | 0.808     | 0.7211    | 
108     | 0.8087    | 0.72      | 
109     | 0.8061    | 0.7194    | 
110     | 0.8065    | 0.7175    | 
111     | 0.8075    | 0.7245    | 
112     | 0.8071    | 0.7213    | 
113     | 0.8078    | 0.7207    | 
114     | 0.8078    | 0.722     | 
115     | 0.8075    | 0.7246    | 
116     | 0.8076    | 0.7236    | 
117     | 0.8076    | 0.7222    | 
118     | 0.8076    | 0.7222    | 
119     | 0.807     | 0.7218    | 
120     | 0.8076    | 0.7218    | 
121     | 0.8076    | 0.7232    | 
122     | 0.807     | 0.7232    | 
123     | 0.8077    | 0.7232    | 
124     | 0.8077    | 0.7232    | 
125     | 0.8076    | 0.7232    | 
126     | 0.8075    | 0.7232    | 
127     | 0.8075    | 0.7232    | 
128     | 0.8081    | 0.7232    | 
129     | 0.8096    | 0.728     | 
130     | 0.8097    | 0.7271    | 
131     | 0.81      | 0.7266    | 
132     | 0.8097    | 0.7195    | 
133     | 0.8115    | 0.7188    | 
134     | 0.8108    | 0.7193    | 
135     | 0.8125    | 0.7193    | 
136     | 0.8121    | 0.7193    | 
137     | 0.8129    | 0.7148    | 
138     | 0.8149    | 0.7148    | 
139     | 0.8167    | 0.7148    | 
140     | 0.8152    | 0.7148    | 
141     | 0.8155    | 0.7148    | 
142     | 0.8155    | 0.7207    | 
143     | 0.8155    | 0.7207    | 
144     | 0.8162    | 0.7207    | 
145     | 0.8169    | 0.7207    | 
146     | 0.8178    | 0.7207    | 
147     | 0.8178    | 0.7217    | 
148     | 0.8185    | 0.723     | 
149     | 0.8186    | 0.723     | 
150     | 0.8187    | 0.723     | 
151     | 0.8183    | 0.723     | 
152     | 0.8205    | 0.7218    | 
153     | 0.8188    | 0.723     | 
154     | 0.8192    | 0.723     | 
155     | 0.8213    | 0.7233    | 
156     | 0.8196    | 0.7178    | 
157     | 0.8207    | 0.7178    | 
158     | 0.8216    | 0.7178    | 
159     | 0.8223    | 0.719     | 
160     | 0.8229    | 0.719     | 
161     | 0.8227    | 0.7189    | 
162     | 0.8224    | 0.718     | 
---------------------------------
Finished sucessfully.
NDCG@5 on training data: 0.7924
NDCG@5 on validation data: 0.7363
---------------------------------

Model saved to: LambdaMART_with_counter
