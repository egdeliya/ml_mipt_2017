{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительный материал для выполнения дз**:\n",
    "- Воронцов К. В. Математические методы обучения по прецедентам. 2012. http://www.machinelearning.ru/wiki/images/6/6d/Voron-ML-1.pdf (разделы 5.2 и 7.1)\n",
    "- Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning. Springer: Data Mining, Inference, and Prediction.  — 2nd ed. — Springer-Verlag. 2009. — 746 p.http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf (глава 14)\n",
    "\n",
    "\n",
    "\n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2017_fall <номер_группы> <фамилия>``, к примеру -- ``ML2017_fall 496 ivanov``\n",
    "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2017_496_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2016_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, и просто не найдем ваше дз, если вы не аккуратно его подпишите.\n",
    "- **PS2**: Дедлайн жесткий, в том числе помтоу что это ДЗ последнее в курсе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Контрольные вопросы (0 % - для самоконтроля) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответе на вопросы своими словами (загугленный материал надо пересказать), ответ обоснуйте (напишите и ОБЪЯСНИТЕ формулки если потребуется), если не выходит, то вернитесь к лекции дополнительным материалам:\n",
    "\n",
    "**Вопрос 1**: В чём заключается проблема мультиколлинеарности?\n",
    "\n",
    "Мультиколлинеарность означает, что некоторые признаки являются линейно зависимыми, то есть матрица объекты - признаки является вырожденной, поэтому у неё есть нулевые собственные значения. Это является проблемой, потому что при решении задачи регрессии методом наименьших квадратов (МНК) ветрор весов выражается через величины, обратно пропорциональные собственным значениям (это следует из сингулярного разложения), значит, если собственные значение близки к нулю или нулевые, то веса будут огромными. Это приводит к неустойчивости решения шумам и переобучению, потому что при небольшом изменении признака, у которого большой вес, очень сильно изменится ответ. Это также приводит к плохой интерпертируемости решения, потому что мы ожидаем, что чем больше у признака вес, тем он значительней. \n",
    "\n",
    "**Вопрос 2**: Какие проблемы при обучении алгоритмов возникают из-за большой размерности пространства признаков?\n",
    "\n",
    "* Мультиколлинеарность\n",
    "* проклятие размерности\n",
    "* плохоя интерпретируемость\n",
    "\n",
    "**Вопрос 3**: В чем суть проклятия размерности?\n",
    "\n",
    "При росте размерности объекты становятся более удаленными друг от друга, т.е например чтобы с большой вероятностью найти несколько ближайших соседей точки $(0,0,...0)$ среди равномерно распределенных точек в $d$-мерном кубе со стороной $[0; 1]$ нужно отступать на расстояния, быстро растущие с ростом $d$.\n",
    "\n",
    "** Вопрос 4**: Какая связь между решением задачи PCA и SVD-разложение матрицы регрессии?\n",
    "\n",
    "Когда мы решаем задачу понижения размерности, мы хотим из исходной $l \\times n $ матрицы $F$ получить $l \\times m$ матрицу $G$, где $m \\leq n$ таким образом, чтобы исходную матрицу $F$ можно было восстановить по $G$ при помощи некоторого линейного преобразования $U$, то есть хотим, чтобы $GU^T$ примерно равнялось $F$. Оказывается, что если $m = n$, то представление $F = GU^T$ совпадает с сингулярным разложением $F = GU^t = VDU^T$, а если $m < n$, то данное представление является приближённым и сингулярное разложение $GU^T$ получается из сингулярного разложения $F$, если отбросить $n-m$ минимальных собственных значений \n",
    "\n",
    "** Вопрос 5**: Почему в tSNE расстояние между парами объектов измеряется \"по-стьюденту\" и как это помогает решить проблему \"скрученности\" (crowding problem)?\n",
    "\n",
    "\n",
    "\n",
    "**Вопрос 6**: На какой идее базируются алгоритмы аггломеративной кластеризации? Напишите формулу Ланса-Вильма\n",
    "\n",
    "Аггломеративная кластеризация основана на идее слияния. Сначала каждый объект считается отдельным кластером, затем на каждой итерации вместо пары самых ближайших кластеров образовывается один, который состоит из их объединения. Пусть $W = U \\cup V$ образован кластерами $V$ и $U$, тогда расстояние между $W$ и другим кластером $S$ определяется по формуле Ланса-Вильма следующим образом:\n",
    "\n",
    "$R(U \\cup V, S) = \\alpha_U R(U, S) + \\alpha_V R(V, S) + \\beta R(U, V) + \\gamma|R(U, S) - R(V, S)|$, где $\\alpha_U, \\alpha_V, \\beta, \\gamma$ - параметры\n",
    "\n",
    "**Вопрос 7**: Какие два шага выделяют в алгоритме кластеризации k-means?\n",
    "\n",
    "* Относим каждый объект к ближайшему центру\n",
    "* Вычисляем новое положение центров\n",
    "\n",
    "**Вопрос 8**: В чём отличия (основные упрощения) k-means от EM-алгоритма кластеризации?\n",
    "\n",
    "* В EM-алгоритме каждому объекту выборки приписывается вероятность попадания к каждому кластеру, в k-means каждому объекту приписывается один кластер \n",
    "* В k-means не настраивается форма кластеров\n",
    "\n",
    "** Вопрос 9 **Какой принцип работы графовых алгоритмов кластеризации?\n",
    "\n",
    "Говорим, что вершины графа - это объекты выборки, а рёбра - это расстояния между объектами. В графовых алгоритмах мы выбираем параметр $R$, если ребро больше чем $R$, то оно удаляется. Оставшиеся связные компоненты и будут искомыми кластерами. Или же мы выбираем параметр $K$ - количество связных компонент и пользуемся алгоритмом кратчайшего незамкнутого пути, когда мы по очереди соединяем все вершины рёбрами, чтобы рёбра были минимальной длины, а потом удаляем $K-1$ самое длинное ребро    \n",
    "\n",
    "** Вопрос 10 **  В чем некорректность постановки задачи кластеризации?\n",
    "\n",
    "* Изначально неизвестно, сколько нужно выделять кластеров.\n",
    "* Кластеризация очень сильно зависит от выбора метрики, которой мы мерим \"похожесть\" объектов\n",
    "* Непонятно, по каким критериям делать кластеризацию\n",
    "-----------\n",
    "PS: Если проверяющий не понял ответ на большинство вопросов, то будет пичалька. Пишите так, чтобы можно было разобраться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1 align=\"center\">Вопросы по теории (30%) </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задача 1 ** \n",
    "Ответьте на вопросы:\n",
    "\n",
    " 1) Как можно не прибегая к визуализации понять, что кластерная структура у данного облака точек отсутствует?\n",
    " 2) Какие из алгоритмов кластеризации могут выделять кластеры с ленточной структурой? \n",
    " 3) Какие алгоритмы кластеризации чувствительны к шуму и перемычкам?\n",
    " 4) Каким образом приближают «центр кластера» в нелинейных пространствах?\n",
    " 5) Каким образом можно определять число кластеров?\n",
    " \n",
    "** Задача 2 **\n",
    "Даны пять точек на числовой оси $X = (1; 5; 7; 8; 8)$, число кластеров равно 2. Рассчитайте ответ алгоритма  K-means (финальные центры кластеров), если начальные центры кластеров c1 = 1, c2 = 10.\n",
    "\n",
    "** Задача 3 **\n",
    "Докажите, что the k-means всегда сходится.\n",
    "\n",
    "** Задача 4 **\n",
    "Для сжатия размерности пространства алгоритм PCA применяется датасету с количеством признаков $D = 100$. Наблюдается следующий спектр собственных значений матрицы объектов-признаков. \n",
    "<img src=\"PCA_lambda.png\" width=\"600\">\n",
    "Ответье на вопросы\n",
    "\n",
    "* 1) Высокая ли эффективная размерность пространства признаков (intrinsic dimensionality) (насколько она близка к 100)?\n",
    "* 2) Можно ли перевести датасет с помощью PCA в пространство меньшей размерности с минимальными потерями точности? Если да, то чему примерно будет равна размернось "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Практическое задание 1 (30%) </h2>\n",
    "Реализуйте PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import inv, norm, eigvals, svd\n",
    "from scipy import diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "'''\n",
    "Performs the Principal Coponent analysis of the Matrix F\n",
    "Matrix must be n * l dimensions\n",
    "where n is # features\n",
    "l is # samples\n",
    "'''\n",
    "\n",
    "def PCA(F, varRetained = 0.95, show = False):\n",
    "    # Input\n",
    "    #     F - initaial matrix \n",
    "    # Compute Covariance Matrix Sigma\n",
    "    # Input\n",
    "    (n, l) = F.shape\n",
    "    Sigma = 1.0 / l * F.dot(np.transpose(F)) \n",
    "    # Compute eigenvectors and eigenvalues of Sigma by SVD\n",
    "    # U, V - matrix, d - array: Sigma = U * np.diag(d) * V\n",
    "    U, d, V = svd(Sigma, full_matrices=False)\n",
    "\n",
    "    # compute the value m: number of minumum features that retains the given variance varRetaine\n",
    "    dTot = np.sum(d)\n",
    "    var_i = np.array([np.sum(d[: i + 1]) / dTot for i in range(n)])\n",
    "    m = np.argmax(var_i >= varRetained)\n",
    "    print '%.2f %% variance retained in %d dimensions' % (var_i[m], m)  \n",
    "\n",
    "    # plot the variance plot\n",
    "    if show:\n",
    "        plt.plot(var_i)\n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel(' Percentage Variance retained')\n",
    "        plt.title('PCA $\\% \\sigma^2 $ vs # features')\n",
    "        plt.show()\n",
    "\n",
    "    # compute the reduced dimensional features by projection\n",
    "    U_reduced = U[:, :m]\n",
    "    G = V[:, :m]*d[:m]\n",
    "\n",
    "    return G, U_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Примените алгоритм к данным MNIST\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA - Principal COmponent Analysis\n",
      "0.95 % variance retained in 15 dimensions\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEaCAYAAAACBmAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa209ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# PCA of training set\n",
    "print 'Performing PCA - Principal COmponent Analysis'\n",
    "\n",
    "Z, U_reduced = PCA(X.T, varRetained = 0.95, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71f5295b119b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mU_reduced\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "print Z\n",
    "print U_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><h2 align=\"center\">Практическое задание 2 (40%) </h2> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"left\">Изучение алгоритмов кластеризации на разных выборках</h2>\n",
    "\n",
    "### Кластеризация цифр с помощью dbscan\n",
    "На данных из sklearn.datasets.load_digits примените алгоритмы кластеризации (знания о метках классов при кластеризации использовать нельзя):\n",
    " - <a href='http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN'>dbscan </a> \n",
    " запускайте при различных параметрах eps и minsamples, для всех экспериментов можете выбрать одну метрику (вспомните семинар про  метрические алгоритмы);\n",
    " - Используя метки классов цифр, оцените качество различных кластеризаций при помощи Adjusted Mutual Information и Adjusted Rand Index. \n",
    " - визуалируйте изображения тех цифр, которые соответствуют core_points;\n",
    " - визуалируйте изображения тех цифр, которые соответствуют выбросам;\n",
    " - сделайте выводы и применимости алгоритмов.\n",
    "\n",
    "### Уменьшение палитры изображения\n",
    " - для <a href=\"https://thumbs.dreamstime.com/x/two-lorikeet-birds-2293918.jpg\"> картинки </a> \n",
    "нужно уменьшить число цветов в палитре; для этого нужно выделить кластеры в пространстве RGB, объекты соответствуют пикселам изображения; после выделения кластеров,\n",
    "все пикселы, отнесенные в один кластер, заполняются одним цветом; этот цвет может быть центроидом соответствующего кластера, медианным цветом по кластеру. \n",
    " - Попробуйте различные алгоритмы кластеризации:\n",
    "        -- KMeans\n",
    "        -- MeanShift\n",
    "        -- AgglomerativeClustering\n",
    "   Рассмотрите число кластеров K = 2, 3, 10, 20\n",
    " - Для различных кластеризаций оцените и сравните потери от уменьшения цветов при помощи\n",
    "метрики <a href=\"http://scikit-image.org/docs/dev/api/skimage.measure.html\"> SSIM</a>. Какой способ оказался лучшим?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
